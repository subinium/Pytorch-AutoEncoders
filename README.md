<h1 align="center">
  <b>PyTorch Autoencoders</b><br>
</h1>

<p align="center">
  <a href="https://www.python.org/">
    <img src="https://img.shields.io/badge/Python-3.8-4B8BBE.svg" /></a>
  <a href= "https://pytorch.org/">
    <img src="https://img.shields.io/badge/PyTorch-1.9-EE4C2C.svg" /></a>
  <a href= "https://github.com/subinium/Pytorch-AutoEncoders/blob/main/LICENSE">
    <img src="https://img.shields.io/badge/license-MIT-yellow.svg" /></a>
</p>

Implementing a Variational Autoencoder (VAE) Series in Pytorch.

> Inspired by this [repository](https://github.com/AntixK/PyTorch-VAE)

## Model List

|check|model|paper|conference|
|-|-|-|-|
|O|**VAE**|[Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)|ICLR 2014|
|O|**CVAE**|[Learning Structured Output Representation using Deep Conditional Generative Models](https://scholar.google.com/scholar_url?url=http://papers.nips.cc/paper/5775-learning-structured-outputrepresentation-using-deep-conditional-generative-models.pdf&hl=ko&sa=T&oi=gsb-gga&ct=res&cd=0&d=12314198516266869942&ei=dUBhYbqGLKXGywS7_I6ABQ&scisig=AAGBfm09qbvL0Wl0zrhnRZMZS7H26bQv4Q)|NeurIPS 2015|
|O|**AAE**|[Adversarial Autoencoder](https://arxiv.org/abs/1511.05644)|ICLR 2016|
|O|**Beta-VAE**|[Î²-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework](https://openreview.net/forum?id=Sy2fzU9gl)|ICLR 2017|
||**VQ-VAE**|[Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937)|NeurIPS 2017|

## Result

> TBD

## Contact

If you have any question about the code, feel free to email me at `subinium@gmail.com`.