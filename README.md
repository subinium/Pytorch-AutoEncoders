<h1 align="center">
  <b>PyTorch Autoencoders</b><br>
</h1>

<p align="center">
  <a href="https://www.python.org/">
    <img src="https://img.shields.io/badge/Python-3.8-4B8BBE.svg" /></a>
  <a href= "https://pytorch.org/">
    <img src="https://img.shields.io/badge/PyTorch-1.7-EE4C2C.svg" /></a>
  <a href= "https://github.com/subinium/Pytorch-AutoEncoders/blob/main/LICENSE">
    <img src="https://img.shields.io/badge/license-MIT-yellow.svg" /></a>
</p>

Implementing a Variational Autoencoder (VAE) Series in Pytorch.

> Inspired by this [repository](https://github.com/AntixK/PyTorch-VAE)

## Model List

- [x] VAE
- [x] CVAE
- [ ] DAE
- [ ] Beta-VAE
- [ ] InfoVAE
- [ ] JointVAE
- [ ] VQ-VAE
- [ ] VQ-VAE-2

## Contact

If you have any question about the code, feel free to email me at `subinium@gmail.com`.